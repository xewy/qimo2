import requests
from lxml import etree
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import streamlit as st
from collections import Counter

# è®¾ç½®matplotlibé»˜è®¤å­—ä½“ä¸ºSimHeiï¼Œä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SIMHEI']  # æŒ‡å®šé»˜è®¤å­—ä½“
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# å®šä¹‰æ•°æ®æ¸…æ´—å‡½æ•°
def clean_text(text):
    text = text.replace('\n', '')
    text = text.replace(' ', '')
    text = text.strip()
    return text

# çˆ¬å–è¯¾ç¨‹ä¿¡æ¯
def get_hbnu_course_info(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        html = etree.HTML(response.text)
        courses = html.xpath('//table//tr')[1:]
        result = []
        for index, course in enumerate(courses, start=1):
            seq = str(index)
            name = course.xpath('./td[3]/a/text()')[0].strip() if course.xpath('./td[3]/a') else 'æ— é“¾æ¥çš„è¯¾ç¨‹åç§°'
            level = course.xpath('./td[4]/text()')[0].strip()
            year = course.xpath('./td[5]/text()')[0].strip()
            department = course.xpath('./td[6]/text()')[0].strip() if course.xpath('./td[6]/text()') else ''
            teacher = course.xpath('./td[7]/text()')[0].strip()
            clicks = course.xpath('./td[8]/text()')[0].strip()
            result.append([seq, name, level, year, department, teacher, clicks])
        df = pd.DataFrame(result, columns=['åºå·', 'è¯¾ç¨‹åç§°', 'è·å¥–çº§åˆ«', 'è·å¥–å¹´åº¦', 'æ‰€å±é™¢ç³»', 'è¯¾ç¨‹è´Ÿè´£äºº', 'ç‚¹å‡»æ¬¡æ•°'])
        df['åºå·'] = pd.to_numeric(df['åºå·'])
        df = df.sort_values(by='åºå·')
        return df
    else:
        st.error("Failed to retrieve the webpage")
        return None

# ç”Ÿæˆè¯äº‘å›¾
def generate_wordcloud(words):
    wordcloud = WordCloud(font_path="C:/Windows/Fonts/msyh.ttc", width=800, height=400, background_color='white').generate(' '.join(words))
    return wordcloud

# æ•°æ®å¯è§†åŒ–åˆ†æå‡½æ•°
def visualize_data(df):
    # è¯¾ç¨‹ç‚¹å‡»æ¬¡æ•°åˆ†å¸ƒ
    st.subheader("è¯¾ç¨‹ç‚¹å‡»æ¬¡æ•°åˆ†å¸ƒ")
    plt.figure(figsize=(10, 6))
    plt.barh(df['è¯¾ç¨‹åç§°'], df['ç‚¹å‡»æ¬¡æ•°'], color='skyblue')
    plt.xlabel('ç‚¹å‡»æ¬¡æ•°')
    plt.title('è¯¾ç¨‹ç‚¹å‡»æ¬¡æ•°åˆ†å¸ƒ')
    st.pyplot(plt)

    # è·å¥–çº§åˆ«åˆ†å¸ƒ
    st.subheader("è·å¥–çº§åˆ«åˆ†å¸ƒ")
    level_counts = df['è·å¥–çº§åˆ«'].value_counts()
    plt.figure(figsize=(8, 6))
    plt.pie(level_counts, labels=level_counts.index, autopct='%1.1f%%')
    plt.title('è·å¥–çº§åˆ«åˆ†å¸ƒ')
    st.pyplot(plt)

    # è¯¾ç¨‹åç§°è¯äº‘
    st.subheader("è¯¾ç¨‹åç§°è¯äº‘")
    all_names = ' '.join(df['è¯¾ç¨‹åç§°'].dropna().astype(str).tolist())
    wordcloud = generate_wordcloud(all_names.split())
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('è¯¾ç¨‹åç§°è¯äº‘')
    st.pyplot(plt)

    # è¯¾ç¨‹åç§°è¯é¢‘ç»Ÿè®¡
    st.subheader("è¯¾ç¨‹åç§°è¯é¢‘ç»Ÿè®¡")
    word_counts = Counter(all_names.split())
    df_word_counts = pd.DataFrame(word_counts.items(), columns=['è¯¾ç¨‹åç§°', 'è¯é¢‘'])
    st.dataframe(df_word_counts)

# ä¸»å‡½æ•°
def main():
    st.set_page_config(page_title="è¯¾ç¨‹ä¿¡æ¯åˆ†æå·¥å…·", page_icon="ğŸ“Š", layout="wide")

    st.title("ğŸ“Š è¯¾ç¨‹ä¿¡æ¯åˆ†æå·¥å…·")
    st.write("è¯·è¾“å…¥å­¦é™¢çš„ç½‘å€ï¼Œæˆ‘ä»¬å°†ä¸ºæ‚¨æå–è¯¾ç¨‹ä¿¡æ¯ï¼Œå¹¶å±•ç¤ºè¯é¢‘ç»Ÿè®¡å’Œå¯è§†åŒ–åˆ†æã€‚")

    url = st.text_input('è¾“å…¥å­¦é™¢ç½‘å€:', '')

    if st.button('å¼€å§‹åˆ†æ'):
        if url:
            st.write("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™...")
            df = get_hbnu_course_info(url)
            if df is not None:
                visualize_data(df)
                st.success("åˆ†æå®Œæˆï¼")
        else:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘å€")

if __name__ == "__main__":
    main()
